{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcfbWmWIlNbz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "data = np.load(\"actions_dataset.npz\")\n",
        "X, y = data[\"X\"], data[\"y\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "better understand the data"
      ],
      "metadata": {
        "id": "z3VcoX-vlaYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "print(\"\\nFirst 5 elements of X:\\n\", X[:5])\n",
        "print(\"\\nFirst 5 elements of y:\\n\", y[:5])\n",
        "unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "unique_classes_x, class_counts_x = np.unique(X, return_counts=True)\n",
        "print(\"\\nUnique classes and their counts in y:\")\n",
        "for class_val, count in zip(unique_classes, class_counts):\n",
        "    print(f\"Class {class_val}: {count}\")\n",
        "print(\"\\nUnique classes and their counts in X:\")\n",
        "for class_val, count in zip(unique_classes_x, class_counts_x):\n",
        "    print(f\"Class {class_val}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtBO9f7VlZRN",
        "outputId": "21934612-9204-45b2-d32e-28669a4d494f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (12428, 5)\n",
            "Shape of y: (12428, 12)\n",
            "\n",
            "First 5 elements of X:\n",
            " [[8 2 8 2 6]\n",
            " [2 8 2 6 2]\n",
            " [8 2 6 2 8]\n",
            " [2 6 2 8 2]\n",
            " [6 2 8 2 8]]\n",
            "\n",
            "First 5 elements of y:\n",
            " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "Unique classes and their counts in y:\n",
            "Class 0.0: 136708\n",
            "Class 1.0: 12428\n",
            "\n",
            "Unique classes and their counts in X:\n",
            "Class 0: 1115\n",
            "Class 1: 1305\n",
            "Class 2: 21487\n",
            "Class 3: 105\n",
            "Class 4: 65\n",
            "Class 5: 3565\n",
            "Class 6: 3805\n",
            "Class 7: 2755\n",
            "Class 8: 24913\n",
            "Class 9: 370\n",
            "Class 10: 845\n",
            "Class 11: 1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss, top_k_accuracy_score\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "# ---- inputs you already have ----\n",
        "# X: shape (N, 5)   integers\n",
        "# y: shape (N, 12)  one-hot\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# 1) prep: one-hot -> labels\n",
        "y_ids = y.argmax(axis=1)\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "# 2) split (use only TRAIN priors to avoid leakage)\n",
        "X_tr, X_te, y_tr_ids, y_te_ids, y_tr_oh, y_te_oh = train_test_split(\n",
        "    X, y_ids, y, test_size=0.2, random_state=42, stratify=y_ids\n",
        ")\n",
        "\n",
        "# 3) compute class priors from TRAIN\n",
        "counts = np.bincount(y_tr_ids, minlength=num_classes).astype(float)\n",
        "priors = counts / counts.sum()  # weighted-random probabilities\n",
        "\n",
        "# optional: Laplace smoothing if any class might be missing in train\n",
        "# priors = (counts + 1.0) / (counts.sum() + num_classes)\n",
        "\n",
        "# 4) RANDOM (uniform) baseline\n",
        "rand_pred_ids = rng.integers(low=0, high=num_classes, size=len(y_te_ids))\n",
        "# probability matrix for log_loss/top-k\n",
        "rand_probs = np.full((len(y_te_ids), num_classes), 1.0 / num_classes)\n",
        "\n",
        "# 5) WEIGHTED-RANDOM (by priors) baseline\n",
        "wrand_pred_ids = rng.choice(num_classes, size=len(y_te_ids), p=priors)\n",
        "# same priors for every row\n",
        "wrand_probs = np.tile(priors, (len(y_te_ids), 1))\n",
        "\n",
        "# 6) metrics\n",
        "def evaluate(y_true_ids, pred_ids, prob_mat, name=\"baseline\", k_list=(3,5)):\n",
        "    out = {\n",
        "        f\"{name}/accuracy\": accuracy_score(y_true_ids, pred_ids),\n",
        "        f\"{name}/macro_f1\": f1_score(y_true_ids, pred_ids, average='macro'),\n",
        "        f\"{name}/micro_f1\": f1_score(y_true_ids, pred_ids, average='micro'),\n",
        "        f\"{name}/log_loss\": log_loss(y_true_ids, prob_mat, labels=np.arange(num_classes)),\n",
        "    }\n",
        "    for k in k_list:\n",
        "        out[f\"{name}/top{k}\"] = top_k_accuracy_score(y_true_ids, prob_mat, k=k, labels=np.arange(num_classes))\n",
        "    return out\n",
        "\n",
        "rand_metrics  = evaluate(y_te_ids, rand_pred_ids,  rand_probs,  name=\"random\")\n",
        "wrand_metrics = evaluate(y_te_ids, wrand_pred_ids, wrand_probs, name=\"weighted_random\")\n",
        "\n",
        "print(\"Class priors (from train):\", np.round(priors, 4))\n",
        "print(\"\\nRANDOM:\", rand_metrics)\n",
        "print(\"\\nWEIGHTED-RANDOM:\", wrand_metrics)\n",
        "\n",
        "# Example: top-3 accuracy for random baseline\n",
        "top3_rand = top_k_accuracy_score(y_te_ids, rand_probs, k=3, labels=np.arange(num_classes))\n",
        "\n",
        "# Example: top-3 accuracy for weighted-random baseline\n",
        "top3_wrand = top_k_accuracy_score(y_te_ids, wrand_probs, k=3, labels=np.arange(num_classes))\n",
        "\n",
        "print(f\"Random baseline Top-3 accuracy: {top3_rand:.4f}\")\n",
        "print(f\"Weighted-random baseline Top-3 accuracy: {top3_wrand:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1mN6B_Sm5zB",
        "outputId": "0b772c9c-ab30-4214-a063-01d16bda082e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class priors (from train): [0.0179 0.021  0.3458 0.0017 0.0011 0.0573 0.0612 0.0444 0.4009 0.0059\n",
            " 0.0136 0.0292]\n",
            "\n",
            "RANDOM: {'random/accuracy': 0.07803700724054706, 'random/macro_f1': 0.047365727419264377, 'random/micro_f1': 0.07803700724054706, 'random/log_loss': 2.484906649788001, 'random/top3': np.float64(0.048672566371681415), 'random/top5': np.float64(0.49396621078037006)}\n",
            "\n",
            "WEIGHTED-RANDOM: {'weighted_random/accuracy': 0.2847948511665326, 'weighted_random/macro_f1': 0.08118566097749759, 'weighted_random/micro_f1': 0.2847948511665326, 'weighted_random/log_loss': 1.568482310667108, 'weighted_random/top3': np.float64(0.8081255028157683), 'weighted_random/top5': np.float64(0.909895414320193)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss, top_k_accuracy_score\n",
        "\n",
        "# ---- inputs you already have ----\n",
        "# X: shape (N, 5)   integers\n",
        "# y: shape (N, 12)  one-hot\n",
        "\n",
        "# use random generator (no fixed seed -> different results each run)\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "# 1) prep: one-hot -> labels\n",
        "y_ids = y.argmax(axis=1)\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "# 2) split (use only TRAIN priors to avoid leakage)\n",
        "X_tr, X_te, y_tr_ids, y_te_ids, y_tr_oh, y_te_oh = train_test_split(\n",
        "    X, y_ids, y, test_size=0.2, random_state=42, stratify=y_ids\n",
        ")\n",
        "\n",
        "# 3) compute class priors from TRAIN\n",
        "counts = np.bincount(y_tr_ids, minlength=num_classes).astype(float)\n",
        "priors = counts / counts.sum()\n",
        "\n",
        "# --------------------------\n",
        "# Baseline probability generators\n",
        "# --------------------------\n",
        "\n",
        "def make_random_probs(n_samples, num_classes, rng):\n",
        "    \"\"\"Uniform random probability distribution per sample.\"\"\"\n",
        "    return rng.dirichlet(np.ones(num_classes), size=n_samples)\n",
        "\n",
        "def make_weighted_random_probs(n_samples, priors, rng, concentration=50):\n",
        "    \"\"\"Random probs centered on class priors.\"\"\"\n",
        "    return rng.dirichlet(priors * concentration, size=n_samples)\n",
        "\n",
        "# --------------------------\n",
        "# Evaluation helper\n",
        "# --------------------------\n",
        "def evaluate(y_true_ids, prob_mat, name=\"baseline\", k_list=(1,3,5)):\n",
        "    pred_ids = prob_mat.argmax(axis=1)\n",
        "    out = {\n",
        "        f\"{name}/accuracy\": accuracy_score(y_true_ids, pred_ids),\n",
        "        f\"{name}/macro_f1\": f1_score(y_true_ids, pred_ids, average='macro'),\n",
        "        f\"{name}/micro_f1\": f1_score(y_true_ids, pred_ids, average='micro'),\n",
        "        f\"{name}/log_loss\": log_loss(y_true_ids, prob_mat, labels=np.arange(num_classes)),\n",
        "    }\n",
        "    for k in k_list:\n",
        "        out[f\"{name}/top{k}\"] = top_k_accuracy_score(\n",
        "            y_true_ids, prob_mat, k=k, labels=np.arange(num_classes)\n",
        "        )\n",
        "    return out\n",
        "\n",
        "# --------------------------\n",
        "# Run baselines\n",
        "# --------------------------\n",
        "\n",
        "# Uniform random\n",
        "rand_probs = make_random_probs(len(y_te_ids), num_classes, rng)\n",
        "rand_metrics = evaluate(y_te_ids, rand_probs, name=\"random\")\n",
        "\n",
        "# Weighted random\n",
        "wrand_probs = make_weighted_random_probs(len(y_te_ids), priors, rng)\n",
        "wrand_metrics = evaluate(y_te_ids, wrand_probs, name=\"weighted_random\")\n",
        "\n",
        "print(\"Class priors (from train):\", np.round(priors, 4))\n",
        "print(\"\\nRANDOM:\", rand_metrics)\n",
        "print(\"\\nWEIGHTED-RANDOM:\", wrand_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhWrGIioAFL",
        "outputId": "677c48a7-b600-4203-d9b5-f04b5e86772c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class priors (from train): [0.0179 0.021  0.3458 0.0017 0.0011 0.0573 0.0612 0.0444 0.4009 0.0059\n",
            " 0.0136 0.0292]\n",
            "\n",
            "RANDOM: {'random/accuracy': 0.07884151246983105, 'random/macro_f1': 0.05135330319296511, 'random/micro_f1': 0.07884151246983105, 'random/log_loss': 2.9888090938761827, 'random/top1': np.float64(0.07884151246983105), 'random/top3': np.float64(0.2578439259855189), 'random/top5': np.float64(0.415526950925181)}\n",
            "\n",
            "WEIGHTED-RANDOM: {'weighted_random/accuracy': 0.3998390989541432, 'weighted_random/macro_f1': 0.07292208200507116, 'weighted_random/micro_f1': 0.3998390989541432, 'weighted_random/log_loss': 1.7087628204160876, 'weighted_random/top1': np.float64(0.3998390989541432), 'weighted_random/top3': np.float64(0.8032984714400644), 'weighted_random/top5': np.float64(0.8849557522123894)}\n"
          ]
        }
      ]
    }
  ]
}